# -*- coding: utf-8 -*-
"""NaiveBayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KrRAqGMBdXYAFeqEEZ3B-IeXUPHkmKUO
"""

from google.colab import drive
drive.mount("/content/drive")

!pip install contractions

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score, KFold
from html.parser import HTMLParser
import re
import contractions
from sklearn.feature_extraction.text import CountVectorizer
from pandas.core.common import flatten
import math
import pickle

# LOADING DATA IN DATAFRAMES
train_df=pd.read_csv('/content/drive/My Drive/sentiment_train.csv')
test_df=pd.read_csv('/content/drive/My Drive/sentiment_test.csv')

# CLEANING OF TWEETS
def cleaning(train_df):
  clean_5=[]
  html_parser = HTMLParser()
  for sent in train_df['5']:
    clean_S = html_parser.unescape(sent)
    clean_S = re.sub(r"@(\s+|\w+)","",clean_S)  #users eliminate
    clean_S = re.sub(r"https?:\/\/.*", "", clean_S)   #urls eliminate
    clean_S = re.sub(r"www.(\w+\.\w+)+", "", clean_S)   #urls eliminate
    clean_S = contractions.fix(clean_S)   #expand
    clean_S = re.sub(r"[lL][eE][tT]'s","let us",clean_S)   #expand
    clean_S = re.sub(r"[cC][aA][nN]'[tT]","cannot",clean_S)  #expand
    clean_S = re.sub(r"[012456789]+","",clean_S)  #digit eliminate
    clean_S = re.sub(r"^[:|;|\-|']","",clean_S)
    clean_S = re.sub(r"\b[xX]+\b","",clean_S)
  #  clean_S = re.sub(r"(\s+|\w)[\-|\->|<\-]*(\s+|w)","",clean_S)
  #  clean_S = re.sub('[|\=~+^\$\,\."\(\)&%_]', '', clean_S)   #junk symbols eliminate
    clean_S = re.sub(r'\.+', '.', clean_S)
    clean_S = re.sub(r'\,+', ',', clean_S)
    clean_S = re.sub(r'\:+', ':', clean_S)
    clean_S = re.sub('[^a-zA-Z3!\?\s\'#:;\-*\\<>\/.,]', '', clean_S)  #to eliminate non ascii character
    clean_S = clean_S.split()
    clean_5.append(clean_S)
  print(len(clean_5))
  return clean_5

clean_tweets=cleaning(train_df[:50000])
# print(total_df.shape)

# TOKENIZING AND LOWERCASING EACH TWEET AFTER CLEANING
def allWordsin_i(df,index):
  df=df[df['0']==index]
  # print(df)
  class_words=list(flatten(df['5']))
  small_class_words=[]
  for word in class_words:
    word = word.lower()
    small_class_words.append(word)
  # print(class_words)
  return small_class_words

# allWordsin_i(u_train_df,0)

# Training Naive Bayes model
def Train_Multinomial():
  clean_tweets=cleaning(train_df[:50000])
  words=clean_tweets
  words=list(flatten(words))
  vocab=set(words)
  vocab_size=len(vocab)
  total_no_tweets=len(train_df[:50000].index)
  # print(len(words))
  # print(len(vocab))
  grp_df=train_df[:50000].groupby('0')
  ll=grp_df['0'].count()
  u_train_df=train_df[:50000]
  u_train_df['5']=clean_tweets[:50000]
  prior={}
  probability={}
  for i in range(len(ll.index)):
    prior[ll.index[i]] = ll.iloc[i]/total_no_tweets
    words_of_class_i = allWordsin_i(u_train_df,ll.index[i])
    class_size = len(words_of_class_i)
    T_C={}
    for word in vocab:
       T_C[word]= words_of_class_i.count(word)
    for word in vocab:
       probability[word+" "+str(ll.index[i])]=(T_C[word]+1)/(class_size+vocab_size)
  return vocab,prior,probability

vocab,prior,probability=Train_Multinomial()   
# print(probability) 
# print(prior)

# DUMPING CONDITIONAL PROBABILITY , PRIOR PROPABABILITY AND VOCABULARY INTO PICKLE
pickleobj = {} 
pickleobj['prior'] = prior
pickleobj['probability'] = probability
pickleobj['vocab'] = vocab 
 
pickle_file = open('/content/drive/My Drive/NaiveBayesPickle.pkl', 'ab') 

pickle.dump(pickleobj, pickle_file)                      
pickle_file.close()

# LOADING CONDITIONAL PROBABILITY , PRIOR PROPABABILITY AND VOCABULARY INTO PICKLE
pickle_file = open('/content/drive/My Drive/NaiveBayesPickle.pkl', 'rb')      
pickleobj = pickle.load(pickle_file) 
vocab = pickleobj['vocab']
prior = pickleobj['prior']
probability = pickleobj['probability']
print(vocab)
print(prior)
print(probability)      
pickle_file.close()

# PREDICT FUNCTION
def TestMultinomial(vocab,prior,probability,d):
# d="ksdfb kQEJDN ADJDK keed"
   words_intweet= d.split()
   all_words=[]
   for word in words_intweet:
     word=word.lower()
     all_words.append(word)
   grp_df=train_df[:50000].groupby('0')
   ll=grp_df['0'].count()
   score={}
   vocab_size = len(vocab)
   for i in range(len(ll.index)):
     score[i] = math.log10(prior[ll.index[i]])
    #  print(math.log10(prior[ll.index[i]]))
     for word in all_words:
      if(word+" "+str(ll.index[i]) not in probability.keys()):
         probability[word+" "+str(ll.index[i])]=1/vocab_size
      score[i] += math.log(probability.get(word+" "+str(ll.index[i])))
  #  print(score[0].getkey())
   if(score[0] > score[1]):
    return 0
   else:
    return 4

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

y_pred=[]
for i in range(50000):
    op=TestMultinomial(vocab,prior,probability,test_df['5'][i])
    y_pred.append(op)

# print(test_df['0'][:7000])
# print(y_pred)
print(accuracy_score(test_df['0'][:50000],y_pred))

# FUNCTION TO PRINT CONFUSION MATRIX IN A FILE 
def calculateparameter(ExpectedTags,PredictedTags):

    l1=list(dict.fromkeys(ExpectedTags))
    l2=list(dict.fromkeys(PredictedTags))    
    #pairs=nltk.FreqDist(pair)

    df=pd.DataFrame(0, columns=l1, index=l2)
    for i in range(0,len(ExpectedTags)):
        df.loc[PredictedTags[i],ExpectedTags[i]]+=1
    #print(df)
    file=open('/content/drive/My Drive/assignment3a/3aNaiveBayesoutput.txt','a+')
    #.savetxt('output.txt', df.values, fmt='%d', delimiter="\t")
    df.to_csv(r'output.txt', header=None, index=None, sep=' ', mode='a')  
    #TP values:
    file.write("\ntagWisePrecision\n")
    df['rowSum']=df.sum(axis=1)
    precision=[]
    recall=[]
    row=[]
    for col in df.columns:
        if col != 'rowSum':
            if col in df.index:
                value=df.loc[col,col]
                precision.append(value/df.loc[col,'rowSum'])
                row.append(col)
                file.write(str(col)+" "+str(value/df.loc[col,'rowSum'])+"\n")
            else:
                value=0
           

    
    total=0
    for i in range(0,len(precision)):
        total+=precision[i]
    r1=total/len(precision)    
    file.write("\nmacro averaged Precision: "+str(total/len(precision))+"\n")    

    file.write("\ntagWiseRecall:\n")
    df.loc['colSum']=df.sum(axis = 0)
    for col in df.columns:
        if col != 'rowSum':
            if col in df.index:
                recall.append(df.loc[col,col]/df.loc['colSum',col])
                file.write(str(col)+" "+str(df.loc[col,col]/df.loc['colSum',col])+"\n")  
            else:
                #recall.append(0)
                file.write(str(col)+" "+str(0)+"\n")
    total=0
    for i in range(0,len(recall)):
        total+=recall[i]    
    r2=total/len(recall)    
    file.write("\nmacro averaged recall: "+str(total/len(recall))+"\n")

    f1score=[]
    file.write("\nF1 score tag wise:")
    for i in range(0,len(recall)):
        if (recall[i]==0 and precision[i] == 0):
            value=0
        else:
            value=(2*recall[i]*precision[i])/(recall[i]+precision[i])
        file.write(str(row[i])+" "+str(value)+"\n")
        f1score.append(value)
    total=0
    for i in range(0,len(f1score)):
        total+=f1score[i]  
    r3=total/len(f1score)    
    file.write("\nmacro averaged f1score: "+str(total/len(f1score))+"\n\n\n")
    value=0
    for col in df.columns:
        if col != 'rowSum':
            if col in df.index:
                value+=df.loc[col,col]
            else:
                value+=0
    file.write("\nAccuracy: "+str(value/df.loc['colSum','rowSum'])+"\n\n\n")  
    r4=value/df.loc['colSum','rowSum']
    return r1, r2,r3,r4

ExpectedTags = test_df['0'][:50000]
PredictedTags = y_pred
r1,r2,r3,r4=calculateparameter(ExpectedTags,PredictedTags)
print("Macro averaged precision : "+str(r1))
print("Macro averaged recall : "+str(r2))
print("Macro averaged f1 score : "+str(r3))
print("Accuracy : "+r4)

